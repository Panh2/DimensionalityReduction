{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panh2/DimensionalityReduction/blob/master/7403.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安装相应包"
      ],
      "metadata": {
        "id": "EnqzvTx3ars3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3CHiGRyUM38",
        "outputId": "aa00ae03-fa6e-4b57-f117-3acce955dc52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy) (1.22.4)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2955 sha256=4a78b4ce0bfe4642eb1c3e501329d4d6158082bd2c14e970e028aa7298ef49d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/e0/3d/9d0c2020c44a519b9f02ab4fa6d2a4a996c98d79ab2f569fa1\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "下载cifar-10数据集,该数据集具有较高的维度（每个样本具有784个特征）"
      ],
      "metadata": {
        "id": "2RpO5oqfavrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!tar -xzvf cifar-10-python.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luxXxkOAUexd",
        "outputId": "9c74fbba-76c8-421f-c9fe-bb76ac74ca9d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-10 13:24:05--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  75.0MB/s    in 2.2s    \n",
            "\n",
            "2023-04-10 13:24:07 (75.0 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "解压数据集"
      ],
      "metadata": {
        "id": "j3yezvzia26I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "导入相关包"
      ],
      "metadata": {
        "id": "cTiNY4BHa8I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "x0QmSGG8a5ad"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "加载数据集"
      ],
      "metadata": {
        "id": "gZP0hK3ja-Je"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lt0bmwa1ULN6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_cifar10(data_folder):\n",
        "    # 训练数据\n",
        "    with open(os.path.join(data_folder, 'data_batch_1'), 'rb') as f:\n",
        "        train_dict = pickle.load(f, encoding='bytes')\n",
        "        X_train = train_dict[b'data']\n",
        "        y_train = np.array(train_dict[b'labels'])\n",
        "        \n",
        "    # 测试数据\n",
        "    with open(os.path.join(data_folder, 'test_batch'), 'rb') as f:\n",
        "        test_dict = pickle.load(f, encoding='bytes')\n",
        "        X_test = test_dict[b'data']\n",
        "        y_test = np.array(test_dict[b'labels'])\n",
        "    \n",
        "    # 将像素值缩放到[0, 1]之间\n",
        "    X_train = X_train / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "最小马氏距离分类器实现"
      ],
      "metadata": {
        "id": "kzR6MWLDbB0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mahalanobis_distance(x, mean, inv_cov):\n",
        "    diff = x - mean\n",
        "    return np.sqrt(np.dot(np.dot(diff, inv_cov), diff.T))\n",
        "\n",
        "def min_mahalanobis_classifier(x, class_means, inv_cov_matrices):\n",
        "    distances = [mahalanobis_distance(x, mean, inv_cov) for mean, inv_cov in zip(class_means, inv_cov_matrices)]\n",
        "    return np.argmin(distances)\n",
        "    "
      ],
      "metadata": {
        "id": "3V6K7HgYWKZZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "读取数据集"
      ],
      "metadata": {
        "id": "X4qNgq04bFI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = '/content/cifar-10-batches-py'\n",
        "X_train, y_train, X_test, y_test = load_cifar10(data_folder)\n"
      ],
      "metadata": {
        "id": "que0ZuEMaZI_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "先使用PCA将784维降至50维，然后用LDA将50维降至9维"
      ],
      "metadata": {
        "id": "Z10I5XPgbHoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "pca = PCA(n_components=10)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# LDA\n",
        "lda = LDA(n_components=9)\n",
        "X_train_lda = lda.fit_transform(X_train, y_train)\n",
        "X_test_lda = lda.transform(X_test)\n"
      ],
      "metadata": {
        "id": "npeimyL6Yw36"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "计算每个类别的均值和协方差矩阵的逆，供计算马氏距离"
      ],
      "metadata": {
        "id": "ttBd5PkhbR-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_means_pca = []\n",
        "class_means_lda = []\n",
        "inv_cov_matrices_pca = []\n",
        "inv_cov_matrices_lda = []\n",
        "\n",
        "for i in range(10):\n",
        "    class_data_pca = X_train_pca[y_train == i]\n",
        "    class_mean_pca = np.mean(class_data_pca, axis=0)\n",
        "    class_means_pca.append(class_mean_pca)\n",
        "\n",
        "    cov_matrix_pca = np.cov(class_data_pca.T)\n",
        "    inv_cov_matrix_pca = np.linalg.pinv(cov_matrix_pca)\n",
        "    inv_cov_matrices_pca.append(inv_cov_matrix_pca)\n",
        "\n",
        "for i in range(10):\n",
        "    class_data_lda = X_train_lda[y_train == i]\n",
        "    class_mean_lda = np.mean(class_data_lda, axis=0)\n",
        "    class_means_lda.append(class_mean_lda)\n",
        "\n",
        "    cov_matrix_lda = np.cov(class_data_lda.T)\n",
        "    inv_cov_matrix_lda = np.linalg.pinv(cov_matrix_lda)\n",
        "    inv_cov_matrices_lda.append(inv_cov_matrix_lda)"
      ],
      "metadata": {
        "id": "IanEgWcuaXGV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "对最终测试数据进行分类（使用最小马氏距离分类器）并计算准确率"
      ],
      "metadata": {
        "id": "7nrXRyF4bfG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_pca = [min_mahalanobis_classifier(x, class_means_pca, inv_cov_matrices_pca) for x in X_test_pca]\n",
        "y_pred_lda = [min_mahalanobis_classifier(x, class_means_lda, inv_cov_matrices_lda) for x in X_test_lda]\n",
        "accuracy_pca= accuracy_score(y_test, y_pred_pca)\n",
        "accuracy_lda= accuracy_score(y_test, y_pred_lda)\n",
        "print(f\"Classification accuracy: {accuracy_pca}\")\n",
        "print(f\"Classification accuracy: {accuracy_lda}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFeWL9spbbvl",
        "outputId": "bcab4913-8d80-4d1d-d904-c07652a8a7d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification accuracy: 0.3274\n",
            "Classification accuracy: 0.2583\n"
          ]
        }
      ]
    }
  ]
}